{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import networkx as nx\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Activation, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, CSVLogger\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {\n",
    "    'epochs': 20,\n",
    "    'neurons_per_layer': 100,\n",
    "    'pca_components': 100,\n",
    "    'number_of_layers': 5,\n",
    "    'save_folder': '500-Nodes',\n",
    "    'regularisation': 0.001,  # L1 regulariser weight, or None\n",
    "#     'regularisation': None,\n",
    "    'threshold_type': 'value',  # 'fraction' or 'value'\n",
    "#     'threshold': 1E-2,  # A number between 0 and 1, or None\n",
    "    'threshold': 0.08, #None\n",
    "    'activation': 'elu',\n",
    "    'dropout': False,\n",
    "    'batch_norm': False,\n",
    "}\n",
    "\n",
    "# Save params\n",
    "os.makedirs(params['save_folder'], exist_ok = True)\n",
    "with open(os.path.join(params['save_folder'], 'params.csv'), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for key, val in params.items():\n",
    "        writer.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained: 0.914\n"
     ]
    }
   ],
   "source": [
    "# Reduce input dimensions\n",
    "pca = PCA(n_components = params['pca_components'])\n",
    "x_train_pca = pca.fit_transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "\n",
    "print(\"Variance explained:\", round(sum(pca.explained_variance_ratio_), 3))\n",
    "\n",
    "with open(os.path.join(params['save_folder'], 'pca.csv'), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['pca_components', params['pca_components']])\n",
    "    writer.writerow(['variance_explained', round(sum(pca.explained_variance_ratio_), 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(hidden_layers = 1, neurons_per_layer = 512, input_dimension = 784, reg = None,\n",
    "             dropout = False, batch_norm = False, activation = 'elu'):\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    reg = None if reg is None else keras.regularizers.l1(reg)\n",
    "    \n",
    "    for i in range(hidden_layers + 1):\n",
    "        if i == 0:\n",
    "            model.add(Dense(neurons_per_layer, input_shape = (input_dimension,), bias = False,\n",
    "                            kernel_regularizer = reg ))\n",
    "        else:\n",
    "            model.add(Dense(neurons_per_layer, bias = False,\n",
    "                            kernel_regularizer = reg ))\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        if dropout:\n",
    "            model.add(Dropout(0.2))\n",
    "        \n",
    "    model.add(Dense(num_classes, activation = 'softmax', bias = batch_norm,\n",
    "                    kernel_regularizer = reg ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               10000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10000     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10000     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10000     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1000      \n",
      "=================================================================\n",
      "Total params: 41,000\n",
      "Trainable params: 41,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aloe8475\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_shape=(100,), kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\aloe8475\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, kernel_regularizer=<keras.reg..., use_bias=False)`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\aloe8475\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg..., use_bias=False)`\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = getModel(hidden_layers = params['number_of_layers'] - 2,\n",
    "                 neurons_per_layer = params['neurons_per_layer'],\n",
    "                 input_dimension = params['pca_components'],\n",
    "                 reg = params['regularisation'],\n",
    "                 dropout = params['dropout'],\n",
    "                 batch_norm = params['batch_norm'],\n",
    "                 activation = params['activation'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSaver(Callback):\n",
    "    def __init__(self, save_folder = 'G1', **other_params):\n",
    "        super().__init__(**other_params)\n",
    "        self.save_folder = save_folder\n",
    "        os.makedirs(os.path.join(self.save_folder, 'weights'), exist_ok = True)\n",
    "        self.ANNadj = {}\n",
    "    \n",
    "    def on_train_begin(self, logs = {}):\n",
    "        self.G, self.edge_list = self.draw(0)\n",
    "        adj = self.get_subgraph_adj(self.G, self.edge_list, weight = None)\n",
    "        self.ANNadj[\"ANN_Adj_Mat_Untrained\"] = adj\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        self.G, self.edge_list = self.draw(epoch + 1)\n",
    "    \n",
    "    def on_train_end(self, logs = {}):\n",
    "        adj = self.get_subgraph_adj(self.G, self.edge_list, weight = None)\n",
    "        self.ANNadj[\"ANN_Adj_Mat_Trained\"] = adj\n",
    "        scipy.io.savemat(os.path.join(self.save_folder, \"ANN_Adj\"), self.ANNadj)\n",
    "    \n",
    "    def draw(self, epoch):\n",
    "        G = nx.Graph()\n",
    "        new_model = export_utils.copy_remove_batchnorm(self.model)\n",
    "        layers = getLayers(new_model)\n",
    "        weights, bias = getLayerWeights(layers)\n",
    "        self.save_weights(weights, epoch)\n",
    "        initialiseGraphNodes(layers, G, bias = bias)\n",
    "        initialiseGraphEdges(weights, G)\n",
    "        pos = getNodePositions(G, last_layer_multiplier = params['neurons_per_layer'] // num_classes,\n",
    "                               last_layer = params['number_of_layers'])\n",
    "        edge_list = drawPlot(G, pos, save_name = '{}/{:02}'.format(self.save_folder, epoch))\n",
    "        return G, edge_list\n",
    "    \n",
    "    def get_subgraph_adj(self, G, edge_list, weight = None):\n",
    "        G_subgraph = G.edge_subgraph(edge_list)\n",
    "        adj = nx.adjacency_matrix(G_subgraph, weight = weight)\n",
    "        return adj\n",
    "    \n",
    "    def save_weights(self, weights, epoch):\n",
    "        for l, w in weights.items():\n",
    "            np.savetxt(\"{}/weights/epoch{:02}-layer{}.csv\".format(self.save_folder, epoch, l), w, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import export_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayers(model):\n",
    "    layers = {}\n",
    "    layer_number = 1\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            layers[layer_number] = layer\n",
    "            layer_number += 1\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayerWeights(layers):\n",
    "    weights = {}\n",
    "    bias = {}\n",
    "    for i in range(1,len(layers)+1):\n",
    "        weight = layers[i].get_weights()\n",
    "        if isinstance(weight, list):\n",
    "            weights[i] = weight[0]\n",
    "            if len(weight) > 1:\n",
    "                bias[i] = weight[1]\n",
    "        else:\n",
    "            weights[i] = weight  # Seems unnecessary\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseGraphNodes(layers, G, bias = None):\n",
    "    for i, layer in layers.items():\n",
    "        if i == 1:  # First hidden layer\n",
    "            nodes = [\"{}-{}\".format(i-1, n) for n in range(layer.input_shape[1])]\n",
    "            G.add_nodes_from(nodes)\n",
    "        if bias is not None and i in bias:\n",
    "            nodes = [(\"{}-{}\".format(i, n), {'bias': b}) for n, b in enumerate(bias[i])]\n",
    "        else:\n",
    "            nodes = [\"{}-{}\".format(i, n) for n in range(layer.units)]\n",
    "        G.add_nodes_from(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseGraphEdges(weights, G):\n",
    "    edges = []\n",
    "    for layer, weight in weights.items():\n",
    "        rows, columns = weight.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(columns):\n",
    "                edge = (\"{}-{}\".format(layer-1, i), \"{}-{}\".format(layer, j), {'weight': weight[i,j]})\n",
    "                edges.append(edge)\n",
    "        \n",
    "    G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodePositions(G, last_layer_multiplier = 5, last_layer = None):\n",
    "    pos = {}\n",
    "    for node in G.nodes():\n",
    "        split = node.split('-')\n",
    "        layer = int(split[0])\n",
    "        neuron = int(split[1])\n",
    "        pos[node] = np.array( [layer, neuron * (last_layer_multiplier if layer == last_layer else 1)] )\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEdgeColour(G, threshold_by_value = None, threshold_by_fraction = None):\n",
    "    edge_list = []\n",
    "    edge_color = []\n",
    "    for (u, v, w) in G.edges.data('weight'):\n",
    "        if threshold_by_value is None or abs(w) > threshold_by_value:\n",
    "            edge_list.append((u,v))\n",
    "            edge_color.append(w)\n",
    "    if threshold_by_fraction is not None:\n",
    "        n = round(len(edge_list) * threshold_by_fraction)\n",
    "        edge_color = np.array(edge_color)\n",
    "        sort_order = np.argsort(np.abs(edge_color))\n",
    "        edge_color = edge_color[sort_order[-n:]]\n",
    "        edge_color = edge_color.tolist()\n",
    "        edge_list = [edge_list[i] for i in sort_order[-n:]]\n",
    "    return edge_list, edge_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeColour(G):\n",
    "    node_color = []\n",
    "    for (n, b) in G.nodes.data('bias'):\n",
    "        if b is None:\n",
    "            node_color.append(0)\n",
    "        else:\n",
    "            node_color.append(b)\n",
    "    return node_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPlot(G, pos, save_name = None, show_plot = False):\n",
    "    fig, ax = plt.subplots(figsize = [18, 8])\n",
    "    threshold_option = {'threshold_by_{}'.format(params['threshold_type']): params['threshold']}\n",
    "    edge_list, edge_color = getEdgeColour(G, **threshold_option)\n",
    "    edge_cmap = plt.cm.RdBu\n",
    "    edge_vmax = max(np.abs(edge_color))\n",
    "    edge_vmin = -edge_vmax\n",
    "    node_color = getNodeColour(G)\n",
    "    node_cmap = plt.cm.viridis  # plt.cm.PRGn\n",
    "    node_vmax = max(np.abs(node_color)) + 1E-12\n",
    "    node_vmin = -node_vmax\n",
    "\n",
    "\n",
    "    nx.draw_networkx(G, pos, with_labels = False, node_size = 50, edgelist = edge_list, edge_color = edge_color,\n",
    "                     edge_cmap = edge_cmap, edge_vmin = edge_vmin, edge_vmax = edge_vmax, node_color = node_color,\n",
    "                     cmap = node_cmap, vmax = node_vmax, vmin = node_vmin)\n",
    "    sm = plt.cm.ScalarMappable(cmap = edge_cmap, norm = plt.Normalize(vmin = edge_vmin, vmax = edge_vmax))\n",
    "    sm._A = []\n",
    "    plt.colorbar(sm, label = 'Edge weight')\n",
    "    if params['batch_norm']:\n",
    "        sm_1 = plt.cm.ScalarMappable(cmap = node_cmap, norm = plt.Normalize(vmin = node_vmin, vmax = node_vmax))\n",
    "        sm_1._A = []\n",
    "        plt.colorbar(sm_1, label = 'Bias')\n",
    "    plt.title(\"Threshold by {} = abs({})\".format(params['threshold_type'], params['threshold']))\n",
    "    \n",
    "    if save_name is not None:\n",
    "        if not save_name.endswith('.png'):\n",
    "            save_name += '.png'\n",
    "        plt.savefig(save_name, dpi = 200)\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aloe8475\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)\n",
      "  if cb.is_numlike(alpha):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 2.3699 - acc: 0.8832 - val_loss: 1.2366 - val_acc: 0.9134\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.0064 - acc: 0.9158 - val_loss: 0.8341 - val_acc: 0.9256\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.7698 - acc: 0.9262 - val_loss: 0.6981 - val_acc: 0.9344\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.6708 - acc: 0.9340 - val_loss: 0.6222 - val_acc: 0.9402\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.6122 - acc: 0.9386 - val_loss: 0.5797 - val_acc: 0.9411\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.5730 - acc: 0.9412 - val_loss: 0.5479 - val_acc: 0.9448\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.5447 - acc: 0.9439 - val_loss: 0.5239 - val_acc: 0.9464\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.5228 - acc: 0.9453 - val_loss: 0.5055 - val_acc: 0.9479\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.5063 - acc: 0.9470 - val_loss: 0.4887 - val_acc: 0.9515\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4913 - acc: 0.9483 - val_loss: 0.4773 - val_acc: 0.9512\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4798 - acc: 0.9492 - val_loss: 0.4682 - val_acc: 0.9518\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4709 - acc: 0.9500 - val_loss: 0.4636 - val_acc: 0.9528\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.4635 - acc: 0.9504 - val_loss: 0.4518 - val_acc: 0.9540\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4559 - acc: 0.9512 - val_loss: 0.4440 - val_acc: 0.9546\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4489 - acc: 0.9520 - val_loss: 0.4401 - val_acc: 0.9520\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.4427 - acc: 0.9529 - val_loss: 0.4320 - val_acc: 0.9524\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4362 - acc: 0.9530 - val_loss: 0.4289 - val_acc: 0.9541\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4310 - acc: 0.9527 - val_loss: 0.4211 - val_acc: 0.9552\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.4261 - acc: 0.9535 - val_loss: 0.4197 - val_acc: 0.9539\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.4217 - acc: 0.9538 - val_loss: 0.4159 - val_acc: 0.9524\n",
      "Test loss: 0.4158904040336609\n",
      "Test accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "# Fit and test\n",
    "graphSaver = GraphSaver(params['save_folder'])\n",
    "csv_logger = CSVLogger(os.path.join(params['save_folder'], 'history.csv'), append = False)\n",
    "\n",
    "history = model.fit(x_train_pca, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = params['epochs'],\n",
    "                    verbose = 1,\n",
    "                    callbacks = [graphSaver, csv_logger],\n",
    "                    validation_data = (x_test_pca, y_test))\n",
    "score = model.evaluate(x_test_pca, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing fraction 0.9683 from layer 1\n",
      "Removing fraction 0.9865 from layer 2\n",
      "Removing fraction 0.9925 from layer 3\n",
      "Removing fraction 0.9929 from layer 4\n",
      "Removing fraction 0.911 from layer 5\n"
     ]
    }
   ],
   "source": [
    "# Test with loaded weights\n",
    "folder = os.path.join(params['save_folder'], 'weights')\n",
    "weights = {}\n",
    "for f in os.listdir(folder):\n",
    "    if f.endswith('.csv') and f.startswith('epoch{:02}'.format(params['epochs'])):\n",
    "        layer = f[-5:-4]\n",
    "        w = np.loadtxt(os.path.join(folder, f), delimiter = ',')\n",
    "        # Test out thresholding\n",
    "        threshold = 0.08\n",
    "        print(\"Removing fraction {} from layer {}\".format(np.mean(np.abs(w) < threshold), layer))\n",
    "        w[np.abs(w) < threshold] = 0\n",
    "        weights[layer] = w\n",
    "        \n",
    "def activation(x, type):\n",
    "    if type == 'elu':\n",
    "        out = x\n",
    "        out[x < 0] = np.exp(x[x < 0]) - 1  # f(x) =  alpha * (exp(x) - 1.) for x < 0, here alpha = 1\n",
    "    else:\n",
    "        raise Exception(\"Activation type unknown\")\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9386\n"
     ]
    }
   ],
   "source": [
    "X = x_test_pca\n",
    "for l in range(1, params['number_of_layers'] + 1):\n",
    "    X = np.dot(X, weights[str(l)])\n",
    "    X = activation(X, type = params['activation'])\n",
    "\n",
    "y = np.argmax(X, axis = 1)\n",
    "print('Accuracy = {:.4f}'.format(np.mean(y == np.argmax(y_test, axis = 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
