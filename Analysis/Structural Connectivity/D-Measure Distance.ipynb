{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/suphys/aloe8475\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/import/silo2/aloe8475/Documents/edamame\n"
     ]
    }
   ],
   "source": [
    "cd \"Documents/edamame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat, savemat\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import datetime\n",
    "import networkx as nx\n",
    "from edamame import *\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import edamame.core.wires as wires\n",
    "from random import choice\n",
    "from IPython.core.debugger import set_trace\n",
    "from collections import Counter\n",
    "from scipy import sparse\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python 3:\n",
    "import pickle \n",
    "import _pickle as cPickle\n",
    "# import cPickle\n",
    "import gzip\n",
    "def compressed_pickle(obj, filename,protocol=-1):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        cPickle.dump(obj, f, protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_pickle(file):\n",
    "    with gzip.open(file, 'rb') as f:\n",
    "        loaded_object = cPickle.load(f)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/import/silo2/aloe8475/Documents/CODE/Analysis/Functional Connectivity/Functional Tasks\n"
     ]
    }
   ],
   "source": [
    "cd \"/import/silo2/aloe8475/Documents/CODE/Analysis/Functional Connectivity/Functional Tasks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='networks_LinearTransformation.pkl'\n",
    "# print \"Loading Networks\"\n",
    "file = open(name, 'rb')\n",
    "#     [ASN300,cluster1,cluster2,cluster3,time_index,nodesList] = pickle.load(file)\n",
    "#     [ASN300,cluster1,cluster2,cluster3] = pickle.load(file)\n",
    "[ASN300] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=[]\n",
    "for i in range(len(ASN300)):\n",
    "    for j in range(len(ASN300[i])):\n",
    "        g.append(ASN300[i][j]['G'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "schieber.py\n",
    "-----------\n",
    "\n",
    "Python implementation of the distance method in 'Quantification of network\n",
    "structural dissimilarities', by Schieber et al.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def jensen_shannon(dists):\n",
    "    \"\"\"Jensen-Shannong entropy of a family of distributions.\n",
    "\n",
    "    dists is a N by M matrix where each row is the ditribution over a set\n",
    "    of M elements.\n",
    "\n",
    "    \"\"\"\n",
    "    size = dists.shape[0]\n",
    "    vec = np.log(dists.sum(axis=0)) - np.log(size)\n",
    "    first_term = (-1/size) * dists.dot(vec).sum()\n",
    "    second_term = entropy(dists.T).mean()\n",
    "    return first_term - second_term\n",
    "\n",
    "\n",
    "def nnd(graph, dists=None):\n",
    "    \"\"\"Compute Network Node Dispersion (NND).\"\"\"\n",
    "    if dists is None:\n",
    "        dists = node_distance(graph)\n",
    "    diam = dists.shape[1]\n",
    "    return jensen_shannon(dists) / np.log(diam + 1)\n",
    "\n",
    "\n",
    "def node_distance(graph):\n",
    "    \"\"\"All shortest path distances.\n",
    "\n",
    "    The nodes must be labeled by integers from 0 to graph.order() - 1.\n",
    "\n",
    "    \"\"\"\n",
    "    size = graph.order()\n",
    "    if size < 2:\n",
    "        return 1\n",
    "\n",
    "    result = np.zeros((size, size)) # does this need to be sparse?\n",
    "    dists = dict(nx.shortest_path_length(graph))  \n",
    "    dists = np.array([[dists[n1][n2] if dists[n1][n2] < np.inf else size\n",
    "                       for n2 in dists[n1]]\n",
    "                      for n1 in dists])\n",
    "\n",
    "    for idx, row in enumerate(dists):\n",
    "        counts = Counter(row)\n",
    "        result[idx] = [counts[l] for l in range(size)]\n",
    "\n",
    "    diam = (result.sum(axis=0) > 0).sum()\n",
    "    result = result[:, :diam]\n",
    "\n",
    "    return result / size\n",
    "\n",
    "\n",
    "def alpha_centrality(graph, normalize=False):\n",
    "    \"\"\"Bonacich centrality.\"\"\"\n",
    "    size = graph.order()\n",
    "    degrees = graph.degree()\n",
    "    degrees = np.array([degrees[n] for n in graph.nodes()]) / (size - 1)\n",
    "    alpha = 1 / size\n",
    "    exogenous = degrees\n",
    "    mat = sparse.identity(size) - alpha * nx.adjacency_matrix(graph).T\n",
    "    res = sparse.linalg.inv(mat.asformat('csc')).dot(exogenous)\n",
    "    return res if not normalize else res / res.sum()\n",
    "\n",
    "\n",
    "def pad(array, num_cols):\n",
    "    \"\"\"Pad with all-zero columns.\"\"\"\n",
    "    rows = array.shape[0]\n",
    "    cols_to_add = num_cols - array.shape[1]\n",
    "    return np.hstack([array, np.zeros((rows, cols_to_add))])\n",
    "\n",
    "\n",
    "def schieber(graph1, graph2, w1, w2, w3=None, complement=False):\n",
    "    \"\"\"Distance between two graphs. See eqn 2 in the paper.\"\"\"\n",
    "    dists1 = node_distance(graph1)\n",
    "    dists2 = node_distance(graph2)\n",
    "    if dists1.shape[1] > dists2.shape[1]:\n",
    "        pad(dists2, dists1.shape[1])\n",
    "    elif dists2.shape[1] > dists1.shape[1]:\n",
    "        pad(dists1, dists2.shape[1])\n",
    "\n",
    "    first_term = np.vstack([dists1.mean(axis=0), dists2.mean(axis=0)])\n",
    "    first_term = w1 * np.sqrt(jensen_shannon(first_term) / np.log(2))\n",
    "\n",
    "    second_term = np.sqrt(nnd(graph1, dists1)) - np.sqrt(nnd(graph2, dists2))\n",
    "    second_term = w2 * np.abs(second_term)\n",
    "\n",
    "    if w3 is not None:\n",
    "        alpha1 = alpha_centrality(graph1, normalize=True)\n",
    "        alpha2 = alpha_centrality(graph2, normalize=True)\n",
    "        all_alphas = np.vstack([alpha1, alpha2])\n",
    "        third_term = np.sqrt(jensen_shannon(all_alphas) / np.log(2))\n",
    "        if complement:\n",
    "            alpha_comp1 = alpha_centrality(nx.complement(graph1), normalize=True)\n",
    "            alpha_comp2 = alpha_centrality(nx.complement(graph2), normalize=True)\n",
    "            all_alphas = np.vstack([alpha_comp1, alpha_comp2])\n",
    "            third_term += np.sqrt(jensen_shannon(all_alphas) / np.log(2))\n",
    "        third_term = w3 * third_term / 2\n",
    "        return first_term + second_term + third_term\n",
    "    else:\n",
    "        return first_term + second_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize graphs:\n",
    "def pad_graphs(arrs): #find differences \n",
    "    lens = [len(i) for i in arrs]\n",
    "    arr = np.ma.empty((np.max(lens),len(arrs)))\n",
    "    arr.mask = True\n",
    "    for idx, l in enumerate(arrs):\n",
    "        arr[:len(l),idx] = l\n",
    "    return(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.adjacency_matrix(g[i]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0., nan],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0., nan],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0., nan],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., nan],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0., nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(nx.adjacency_matrix(g[i]).todense(),(0,1),'constant', constant_values=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs=[]\n",
    "for i in range(len(g)):\n",
    "    if len(g[i])<300:\n",
    "        graphs.append((np.pad(nx.adjacency_matrix(g[i]).todense(),(0,1),'constant', constant_values=np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-f78be947efea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschieber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# graph = nx.barabasi_albert_graph(200,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-fa9791dbc76a>\u001b[0m in \u001b[0;36mschieber\u001b[0;34m(graph1, graph2, w1, w2, w3, complement)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mfirst_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdists1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mfirst_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjensen_shannon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_term\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "\"\"\"Compute distance between pre-computed graphs.\"\"\"\n",
    "D=[]\n",
    "for i in range(len(g)):\n",
    "    for j in range(len(g)):\n",
    "        D.append(schieber(g[i],g[j],0.45, 0.45, 0.1,True))\n",
    "\n",
    "# graph = nx.barabasi_albert_graph(200,5)\n",
    "# print(schieber(graph, graph, 0.5, 0.5))\n",
    "# print(schieber(graph, graph, 0.45, 0.45, 0.1))\n",
    "# print(schieber(graph, graph, 0.45, 0.45, 0.1, True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
